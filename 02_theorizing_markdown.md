#Week 2: Theorizing Markdown

Text - Author - Code -> and then, citizenship

Tactile perception of textuality. Just so that we don't fall for the illusion that textuality is all the same.

Implications beyond any choice - what tool am I going to use? Individual - practical - and collective - political! - implications.

Beyond individual and political, our choices might even have PHENOMENOLOGICAL implications - remember Heidegger.

How are electronic instruments types of ENFRAMING? Zuhandichkeit - Heidegger's word for how handling is structuring?

Problem - how to organize stuff? Organizing my own private files has repercussions onto an editorial level. Production of knowledge as a material problem. Production of knowledge as me sitting in front of this very screen - this white sheet, this set of fonts, this blinking bar indicating the end of the current sentence. This is, right now, influencing my production.

Text and documents are considered as finished products. We think of them as POINTS. Instead, we should start seeing them as VECTORS. Not a destination - not a finite, determined, immutable destination - but a direction, a vector - something that is moving ahead. In fact, we could think of ANY TEXT as a VECTOR - including Shakespeare, constantly pushed forward from the moment of its production to any future time that will know his works.

Of course! Consider also editorial concerns - philology in a traditional sense - and picture each stage of textual production - from the draft to each more or less legitimate edition, as part of a single draft. Shakespeare is a vector exactly as a pdf.

Now, try imagining each file within my computer as a vector:

- an e-mail

    ----------------------------->

- a term paper

    ----------------------------->

- bibliography

    ----------------------------->

Each vector has a particular set of affordances (?); each can be researched through a specific system. How do I store, back up and share these items, these vectors? Besides research, there are levels such as encryption (?) and access. Companies like Google or Amazon take care of each vector for us: they handle research, encryption and back up for us.

Whenever we decide to prefer a specific format to any other - I.E., write my paper using Word - I am pushed along a technological path that excludes any other option.

These multiplication of mutually exclusive vectors creates a dispersal and an entanglement.

Dennis' proposal: you should try and have as many of these originating points together. For instance, what if I wanted to search through all of these vectors, but they had no common origin?

One option: to sacrifice all of my texts and possessions to a single proprietary system - such as Google. But this entails a risk.

Definition of a computer: it's a machine that can emulate any other machine (tractor, spaceship, [crusade?]).

Emulation of a crusade: 

`if	crusade; then	millennium`.

Files that are human readable. Files that are not human readable. Then simple binary code. What levels can I control? The most primitive level is, of course, hardware. If we had to control every single step, we should probably build computers ourselves - own any interaction at any level.

Potential - unification of the vectors, so that any operation could be possible among them.

What is the solution? The solution is probably to transform all our files into plaintext files. I there were no proprietary file formats, we would just have a collection of plaintext that are longlasting and free.

What is the originating point of my vector, than? It is probably this very moment - the production of a text.

Even though we might be forced to adhere to what departments and publishing companies ask from us, but we might still control at least the source text, so that it will remain flexible and under our control.

Is plaintext apolitical? What sort of question is that? It allows us to control what we are writing. Therefore, if you want, plaintext is the first step towards something that is political.

The "Espionage Act" of 1993 (?!) forbids the teaching of encryption without military authorization - it is a dangerous technology, a weapon. Turing, like many of his peers of the time, was working for the military authorities with the Enigma Project. Much of the technological developments of the second half of the century depended on this coalition between scientists and military forces - for instance, the Internet.

[Another digression: minimal computing; .pdfs can't really be read in Africa: it is a propretary format that requires a certain standard of software.]

Unification of our textual activities: the project for the next few sessions.

Dennis' brief idea about MS Word: it has too broad of an audience. As it tries to please everyone, it actually pleases nobody.

Now let us try addressing a fundamental aspect of what we are doing, of what we will keep doing - FORM and CONTENT. Is there such thing as pure CONTENT, though? Let us not digress again and linger on literary matters. FORM and CONTENT do exist in IT.

Word works through the combination - the constant combination - of FORM and CONTENT. What is being written is also, constantly, being formatted. What you see is what you get. Any information regarding the FORMAT is actually stored somewhere beyond my text - there is a different sheet of content hidden beyond my own. A secret content that is format, and that is often only understandable by the proprietary format that produced it (see, again, the quintessential example: MS Word).

We have the illusion of controlling typesetting whenever we write something in MS Word or any other WYSIWYG software - we are not. Typesetting is in most cases controlled by different software houses that are somewhere else. A publishing house would usually just strip the text from any sort of formatting that I applied to it, and reformat it with their own typesetting software.

The ENFRAMING of Mark-Up: have a look at HTML and understand how mark-up works. Combination: a semantic unit compared with a formal unit. HTML is concerned about the semantics of form. What is a paragraph, what is a title, what is emphasis - and so on. HTML only stores content, even that level of content that might actually influence form. But it does not say what will happen with fonts and visualization. That is stored within a .css.

Problem with XML: it is impossible to write a paper with HTML or XML - if we had to mark everything up, it would take us more time to write a paper than usual - we would eventually spend more time formatting than writing or conceiving what we are going to write.

How do we differentiate semantics from pure form? We have to be concerned with the meaning of what we are writing, not with its formatting. HTML, however, does not do that purely: it still includes purely formal elements (italics and bold) within a set of apparently semantic markers (paragraph, title, quote). In a way, the problem with this mixture is that we always what to control levels that hardly belong to the realm of sole content. HTML is gunky; it does not operate its distinction as beautifully as it should (semantics - style - content - form?); it is not truly human readable.

MARKDOWN was born precisely to solve these problems: to achieve a neat separation between form, content (and style), and to have a clean, readable file.

Markup has implications for both technology and politics.

MARKDOWN is an incredibly popular format right now.
